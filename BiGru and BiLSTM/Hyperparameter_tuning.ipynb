{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1debcd3",
   "metadata": {},
   "source": [
    "# SC4002 Assignment - Part 3.1: Hyperparameter Tuning (Round 2)\n",
    "\n",
    "**Team 3: Aaron Chen & Javier Tin**\n",
    "\n",
    "This notebook performs a **refined, reproducible grid search** to find the optimal hyperparameters for our BiLSTM and BiGRU models.\n",
    "\n",
    "**Updates in this version:**\n",
    "1.  **SEED = 42:** All training is now seeded for reproducible results.\n",
    "2.  **Refined Grid:** Based on the results of the first 216-combination run, this grid is now focused on the most promising parameter ranges (e.g., more layers, specific dropout, and small weight decay). This reduces the search space to **108 combinations**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce7ee6",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "This cell imports all data from our compliant `data_pipeline.py` and sets the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting global random seed to 42 ---\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\nlp_project\\Lib\\site-packages\\torchtext\\vocab.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Successfully imported data pipeline.\n",
      "  - Using device: cuda\n",
      "  - Batch Size: 64\n"
     ]
    }
   ],
   "source": [
    "# === Core PyTorch Imports ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === Plotting Imports ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets the random seed for full reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # --- NEW/UPDATED LINES ---\n",
    "    # Force deterministic algorithms\n",
    "    torch.use_deterministic_algorithms(True) \n",
    "    \n",
    "    # Configure CUDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    \n",
    "    # Set environment variables\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # This is often needed for deterministic bmm/RNNs on GPU\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "    # --- END NEW/UPDATED LINES ---\n",
    "\n",
    "# --- Put this at the TOP of your script ---\n",
    "SEED = 42  # You can pick any number\n",
    "set_seed(SEED)\n",
    "\n",
    "# ... now run the rest of your notebook ...\n",
    "\n",
    "# === Check PyTorch and CUDA Versions ===\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# === Data Pipeline Import ===\n",
    "try:\n",
    "    from data_pipeline import (\n",
    "        train_iterator, \n",
    "        valid_iterator, \n",
    "        test_iterator, \n",
    "        TEXT, \n",
    "        LABEL, \n",
    "        create_embedding_layer,\n",
    "        device,\n",
    "        BATCH_SIZE\n",
    "    )\n",
    "    print(\"\\n✓ Successfully imported data pipeline.\")\n",
    "    print(f\"  - Using device: {device}\")\n",
    "    print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "except ImportError:\n",
    "    print(\"--- ERROR ---\")\n",
    "    print(\"Could not find 'data_pipeline.py'.\")\n",
    "    print(\"Please make sure 'data_pipeline.py' is in the same directory as this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f13e2",
   "metadata": {},
   "source": [
    "## 2. Define Refined Hyperparameter Grid\n",
    "\n",
    "Based on the first run, we observed:\n",
    "- **Hidden Dim:** 256 and 512 were the best. We'll add 384.\n",
    "- **Layers:** 1 layer was almost always worse. We'll focus on 2 and 3.\n",
    "- **Dropout:** 0.7 was often too high. We'll test 0.4, 0.5, 0.6.\n",
    "- **Weight Decay:** 0 and 1e-4 were clear losers. We'll focus on the area around 1e-5 and 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaeb200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations to test: 162\n",
      "\n",
      "--- First 3 Combinations ---\n",
      "{'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "{'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "{'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n"
     ]
    }
   ],
   "source": [
    "# Previous Grid:\n",
    "# param_grid = {\n",
    "#     'model_type': ['BiLSTM', 'BiGRU'],\n",
    "#     'hidden_dim': [128, 256, 512],\n",
    "#     'n_layers': [1, 2, 3],\n",
    "#     'dropout': [0.5, 0.6, 0.7],\n",
    "#     'weight_decay': [0, 1e-4, 1e-5, 1e-6]\n",
    "# } # Total: 216 combinations\n",
    "\n",
    "# Refined Grid (Round 2):\n",
    "param_grid = {\n",
    "    'model_type': ['BiLSTM', 'BiGRU'],\n",
    "    'hidden_dim': [256, 384, 512],\n",
    "    'n_layers': [2, 3, 4],\n",
    "    'dropout': [0.4, 0.5, 0.6],\n",
    "    'weight_decay': [5e-6, 1e-5, 5e-5] \n",
    "}\n",
    "\n",
    "# Create all combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "hyperparam_combos = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"Total combinations to test: {len(hyperparam_combos)}\")\n",
    "print(\"\\n--- First 3 Combinations ---\")\n",
    "for combo in hyperparam_combos[:3]:\n",
    "    print(combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716c032",
   "metadata": {},
   "source": [
    "## 3. Model & Training Definitions\n",
    "\n",
    "These are the same models and functions from our previous notebook, modified slightly to accept the hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2fa90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Definitions (BiLSTM & BiGRU) ===\n",
    "\n",
    "class BiRNN_Model(nn.Module):\n",
    "    def __init__(self, model_type, emb_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = create_embedding_layer(freeze=False) # Keep this compliant\n",
    "        \n",
    "        RNN_CLASS = nn.LSTM if model_type == 'BiLSTM' else nn.GRU\n",
    "        \n",
    "        self.rnn = RNN_CLASS(\n",
    "            input_size=emb_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=n_layers, \n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if n_layers > 1 else 0,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(fc_input_dim, output_dim)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, lengths):\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths.to('cpu'), enforce_sorted=False)\n",
    "        \n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        \n",
    "        # If LSTM, hidden is a tuple (hidden, cell)\n",
    "        if isinstance(hidden, tuple):\n",
    "            hidden = hidden[0] # Just get the hidden state\n",
    "        \n",
    "        last_hidden_state = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        dropped_hidden = self.dropout_layer(last_hidden_state)\n",
    "        prediction = self.fc(dropped_hidden)\n",
    "        return prediction\n",
    "\n",
    "# === Training/Evaluation Function Definitions ===\n",
    "\n",
    "def get_accuracy(preds, y):\n",
    "    top_pred = preds.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train_epoch(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, lengths = batch.text\n",
    "        predictions = model(text, lengths)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, lengths = batch.text\n",
    "            predictions = model(text, lengths)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = get_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47541b39",
   "metadata": {},
   "source": [
    "## 4. Run Grid Search (Round 2)\n",
    "\n",
    "This will loop through all combinations. This cell will still take a while to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efacefe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting REFINED Grid Search for 162 combinations ---),This will take some time.\n",
      "\n",
      "==================== RUN 1/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 1 complete. Time: 0.09m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 2/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 2 complete. Time: 0.08m. Best Valid Acc: 86.46%\n",
      "\n",
      "==================== RUN 3/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 3 complete. Time: 0.08m. Best Valid Acc: 85.33%\n",
      "\n",
      "==================== RUN 4/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 4 complete. Time: 0.08m. Best Valid Acc: 85.42%\n",
      "\n",
      "==================== RUN 5/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 5 complete. Time: 0.08m. Best Valid Acc: 84.72%\n",
      "\n",
      "==================== RUN 6/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 6 complete. Time: 0.08m. Best Valid Acc: 79.34%\n",
      "\n",
      "==================== RUN 7/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 7 complete. Time: 0.08m. Best Valid Acc: 87.07%\n",
      "\n",
      "==================== RUN 8/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 8 complete. Time: 0.08m. Best Valid Acc: 85.50%\n",
      "\n",
      "==================== RUN 9/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 9 complete. Time: 0.08m. Best Valid Acc: 84.46%\n",
      "\n",
      "==================== RUN 10/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 10 complete. Time: 0.10m. Best Valid Acc: 85.59%\n",
      "\n",
      "==================== RUN 11/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 11 complete. Time: 0.10m. Best Valid Acc: 85.16%\n",
      "\n",
      "==================== RUN 12/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 12 complete. Time: 0.10m. Best Valid Acc: 85.50%\n",
      "\n",
      "==================== RUN 13/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 13 complete. Time: 0.10m. Best Valid Acc: 86.46%\n",
      "\n",
      "==================== RUN 14/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 14 complete. Time: 0.11m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 15/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 15 complete. Time: 0.11m. Best Valid Acc: 86.37%\n",
      "\n",
      "==================== RUN 16/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 16 complete. Time: 0.10m. Best Valid Acc: 85.16%\n",
      "\n",
      "==================== RUN 17/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 17 complete. Time: 0.10m. Best Valid Acc: 86.98%\n",
      "\n",
      "==================== RUN 18/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 18 complete. Time: 0.10m. Best Valid Acc: 85.85%\n",
      "\n",
      "==================== RUN 19/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 19 complete. Time: 0.14m. Best Valid Acc: 85.24%\n",
      "\n",
      "==================== RUN 20/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 20 complete. Time: 0.14m. Best Valid Acc: 85.50%\n",
      "\n",
      "==================== RUN 21/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 21 complete. Time: 0.14m. Best Valid Acc: 85.76%\n",
      "\n",
      "==================== RUN 22/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 22 complete. Time: 0.14m. Best Valid Acc: 83.77%\n",
      "\n",
      "==================== RUN 23/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 23 complete. Time: 0.14m. Best Valid Acc: 86.46%\n",
      "\n",
      "==================== RUN 24/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 24 complete. Time: 0.14m. Best Valid Acc: 85.59%\n",
      "\n",
      "==================== RUN 25/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 25 complete. Time: 0.13m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 26/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 26 complete. Time: 0.14m. Best Valid Acc: 84.72%\n",
      "\n",
      "==================== RUN 27/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 27 complete. Time: 0.14m. Best Valid Acc: 86.02%\n",
      "\n",
      "==================== RUN 28/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 28 complete. Time: 0.10m. Best Valid Acc: 87.24%\n",
      "\n",
      "==================== RUN 29/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 29 complete. Time: 0.10m. Best Valid Acc: 85.42%\n",
      "\n",
      "==================== RUN 30/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 30 complete. Time: 0.10m. Best Valid Acc: 85.42%\n",
      "\n",
      "==================== RUN 31/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 31 complete. Time: 0.10m. Best Valid Acc: 86.81%\n",
      "\n",
      "==================== RUN 32/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 32 complete. Time: 0.10m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 33/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 33 complete. Time: 0.10m. Best Valid Acc: 85.76%\n",
      "\n",
      "==================== RUN 34/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 34 complete. Time: 0.10m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 35/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 35 complete. Time: 0.10m. Best Valid Acc: 84.90%\n",
      "\n",
      "==================== RUN 36/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 36 complete. Time: 0.10m. Best Valid Acc: 86.37%\n",
      "\n",
      "==================== RUN 37/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 37 complete. Time: 0.14m. Best Valid Acc: 86.11%\n",
      "\n",
      "==================== RUN 38/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 38 complete. Time: 0.17m. Best Valid Acc: 86.02%\n",
      "\n",
      "==================== RUN 39/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 39 complete. Time: 0.16m. Best Valid Acc: 86.37%\n",
      "\n",
      "==================== RUN 40/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 40 complete. Time: 0.16m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 41/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 41 complete. Time: 0.16m. Best Valid Acc: 86.02%\n",
      "\n",
      "==================== RUN 42/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 42 complete. Time: 0.16m. Best Valid Acc: 86.11%\n",
      "\n",
      "==================== RUN 43/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 43 complete. Time: 0.15m. Best Valid Acc: 86.02%\n",
      "\n",
      "==================== RUN 44/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 44 complete. Time: 0.15m. Best Valid Acc: 88.11%\n",
      "\n",
      "==================== RUN 45/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 45 complete. Time: 0.15m. Best Valid Acc: 84.29%\n",
      "\n",
      "==================== RUN 46/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 46 complete. Time: 0.19m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 47/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 47 complete. Time: 0.19m. Best Valid Acc: 86.20%\n",
      "\n",
      "==================== RUN 48/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 48 complete. Time: 0.20m. Best Valid Acc: 84.64%\n",
      "\n",
      "==================== RUN 49/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 49 complete. Time: 0.19m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 50/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 50 complete. Time: 0.19m. Best Valid Acc: 85.68%\n",
      "\n",
      "==================== RUN 51/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 51 complete. Time: 0.19m. Best Valid Acc: 86.37%\n",
      "\n",
      "==================== RUN 52/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 52 complete. Time: 0.19m. Best Valid Acc: 84.03%\n",
      "\n",
      "==================== RUN 53/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 53 complete. Time: 0.19m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 54/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 54 complete. Time: 0.20m. Best Valid Acc: 87.41%\n",
      "\n",
      "==================== RUN 55/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 55 complete. Time: 0.14m. Best Valid Acc: 86.89%\n",
      "\n",
      "==================== RUN 56/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 56 complete. Time: 0.14m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 57/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 57 complete. Time: 0.14m. Best Valid Acc: 86.28%\n",
      "\n",
      "==================== RUN 58/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 58 complete. Time: 0.14m. Best Valid Acc: 85.68%\n",
      "\n",
      "==================== RUN 59/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 59 complete. Time: 0.14m. Best Valid Acc: 84.64%\n",
      "\n",
      "==================== RUN 60/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 60 complete. Time: 0.14m. Best Valid Acc: 83.94%\n",
      "\n",
      "==================== RUN 61/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 61 complete. Time: 0.15m. Best Valid Acc: 86.81%\n",
      "\n",
      "==================== RUN 62/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 62 complete. Time: 0.14m. Best Valid Acc: 86.63%\n",
      "\n",
      "==================== RUN 63/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 63 complete. Time: 0.14m. Best Valid Acc: 84.11%\n",
      "\n",
      "==================== RUN 64/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 64 complete. Time: 0.22m. Best Valid Acc: 86.37%\n",
      "\n",
      "==================== RUN 65/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 65 complete. Time: 0.22m. Best Valid Acc: 84.55%\n",
      "\n",
      "==================== RUN 66/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 66 complete. Time: 0.21m. Best Valid Acc: 84.98%\n",
      "\n",
      "==================== RUN 67/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 67 complete. Time: 0.22m. Best Valid Acc: 85.24%\n",
      "\n",
      "==================== RUN 68/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 68 complete. Time: 0.22m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 69/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 69 complete. Time: 0.22m. Best Valid Acc: 85.16%\n",
      "\n",
      "==================== RUN 70/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 70 complete. Time: 0.22m. Best Valid Acc: 84.20%\n",
      "\n",
      "==================== RUN 71/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 71 complete. Time: 0.22m. Best Valid Acc: 87.07%\n",
      "\n",
      "==================== RUN 72/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 72 complete. Time: 0.22m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 73/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 73 complete. Time: 0.30m. Best Valid Acc: 87.15%\n",
      "\n",
      "==================== RUN 74/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 74 complete. Time: 0.30m. Best Valid Acc: 86.11%\n",
      "\n",
      "==================== RUN 75/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 75 complete. Time: 0.30m. Best Valid Acc: 86.28%\n",
      "\n",
      "==================== RUN 76/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 76 complete. Time: 0.30m. Best Valid Acc: 86.20%\n",
      "\n",
      "==================== RUN 77/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 77 complete. Time: 0.30m. Best Valid Acc: 86.81%\n",
      "\n",
      "==================== RUN 78/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 78 complete. Time: 0.30m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 79/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 79 complete. Time: 0.30m. Best Valid Acc: 86.63%\n",
      "\n",
      "==================== RUN 80/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 80 complete. Time: 0.30m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 81/162 ====================\n",
      "Params: {'model_type': 'BiLSTM', 'hidden_dim': 512, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 81 complete. Time: 0.30m. Best Valid Acc: 83.16%\n",
      "\n",
      "==================== RUN 82/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 82 complete. Time: 0.08m. Best Valid Acc: 86.63%\n",
      "\n",
      "==================== RUN 83/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 83 complete. Time: 0.08m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 84/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 84 complete. Time: 0.08m. Best Valid Acc: 85.85%\n",
      "\n",
      "==================== RUN 85/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 85 complete. Time: 0.08m. Best Valid Acc: 86.46%\n",
      "\n",
      "==================== RUN 86/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 86 complete. Time: 0.08m. Best Valid Acc: 85.33%\n",
      "\n",
      "==================== RUN 87/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 87 complete. Time: 0.08m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 88/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 88 complete. Time: 0.08m. Best Valid Acc: 86.46%\n",
      "\n",
      "==================== RUN 89/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 89 complete. Time: 0.08m. Best Valid Acc: 86.11%\n",
      "\n",
      "==================== RUN 90/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 90 complete. Time: 0.08m. Best Valid Acc: 85.16%\n",
      "\n",
      "==================== RUN 91/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 91 complete. Time: 0.11m. Best Valid Acc: 85.68%\n",
      "\n",
      "==================== RUN 92/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 92 complete. Time: 0.11m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 93/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 93 complete. Time: 0.11m. Best Valid Acc: 84.46%\n",
      "\n",
      "==================== RUN 94/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 94 complete. Time: 0.11m. Best Valid Acc: 83.07%\n",
      "\n",
      "==================== RUN 95/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 95 complete. Time: 0.11m. Best Valid Acc: 86.28%\n",
      "\n",
      "==================== RUN 96/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 96 complete. Time: 0.11m. Best Valid Acc: 85.24%\n",
      "\n",
      "==================== RUN 97/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 97 complete. Time: 0.11m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 98/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 98 complete. Time: 0.12m. Best Valid Acc: 86.89%\n",
      "\n",
      "==================== RUN 99/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 99 complete. Time: 0.11m. Best Valid Acc: 85.16%\n",
      "\n",
      "==================== RUN 100/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 100 complete. Time: 0.14m. Best Valid Acc: 87.07%\n",
      "\n",
      "==================== RUN 101/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 101 complete. Time: 0.13m. Best Valid Acc: 85.07%\n",
      "\n",
      "==================== RUN 102/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 102 complete. Time: 0.14m. Best Valid Acc: 83.25%\n",
      "\n",
      "==================== RUN 103/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 103 complete. Time: 0.14m. Best Valid Acc: 85.33%\n",
      "\n",
      "==================== RUN 104/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 104 complete. Time: 0.13m. Best Valid Acc: 85.94%\n",
      "\n",
      "==================== RUN 105/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 105 complete. Time: 0.13m. Best Valid Acc: 81.42%\n",
      "\n",
      "==================== RUN 106/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 106 complete. Time: 0.14m. Best Valid Acc: 85.33%\n",
      "\n",
      "==================== RUN 107/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 107 complete. Time: 0.14m. Best Valid Acc: 85.68%\n",
      "\n",
      "==================== RUN 108/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 256, 'n_layers': 4, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 108 complete. Time: 0.13m. Best Valid Acc: 81.77%\n",
      "\n",
      "==================== RUN 109/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 109 complete. Time: 0.10m. Best Valid Acc: 86.28%\n",
      "\n",
      "==================== RUN 110/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 110 complete. Time: 0.10m. Best Valid Acc: 83.85%\n",
      "\n",
      "==================== RUN 111/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 111 complete. Time: 0.10m. Best Valid Acc: 85.24%\n",
      "\n",
      "==================== RUN 112/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 112 complete. Time: 0.10m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 113/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 113 complete. Time: 0.10m. Best Valid Acc: 84.90%\n",
      "\n",
      "==================== RUN 114/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 114 complete. Time: 0.10m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 115/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 115 complete. Time: 0.10m. Best Valid Acc: 87.93%\n",
      "\n",
      "==================== RUN 116/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 116 complete. Time: 0.10m. Best Valid Acc: 87.15%\n",
      "\n",
      "==================== RUN 117/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 2, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 117 complete. Time: 0.10m. Best Valid Acc: 85.50%\n",
      "\n",
      "==================== RUN 118/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 118 complete. Time: 0.13m. Best Valid Acc: 86.63%\n",
      "\n",
      "==================== RUN 119/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 1e-05}\n",
      "Run 119 complete. Time: 0.14m. Best Valid Acc: 82.81%\n",
      "\n",
      "==================== RUN 120/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.4, 'weight_decay': 5e-05}\n",
      "Run 120 complete. Time: 0.14m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 121/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-06}\n",
      "Run 121 complete. Time: 0.14m. Best Valid Acc: 86.11%\n",
      "\n",
      "==================== RUN 122/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 1e-05}\n",
      "Run 122 complete. Time: 0.14m. Best Valid Acc: 86.55%\n",
      "\n",
      "==================== RUN 123/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.5, 'weight_decay': 5e-05}\n",
      "Run 123 complete. Time: 0.14m. Best Valid Acc: 86.72%\n",
      "\n",
      "==================== RUN 124/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-06}\n",
      "Run 124 complete. Time: 0.14m. Best Valid Acc: 86.20%\n",
      "\n",
      "==================== RUN 125/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 1e-05}\n",
      "Run 125 complete. Time: 0.14m. Best Valid Acc: 84.90%\n",
      "\n",
      "==================== RUN 126/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 3, 'dropout': 0.6, 'weight_decay': 5e-05}\n",
      "Run 126 complete. Time: 0.14m. Best Valid Acc: 83.42%\n",
      "\n",
      "==================== RUN 127/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 5e-06}\n",
      "Run 127 complete. Time: 0.18m. Best Valid Acc: 83.51%\n",
      "\n",
      "==================== RUN 128/162 ====================\n",
      "Params: {'model_type': 'BiGRU', 'hidden_dim': 384, 'n_layers': 4, 'dropout': 0.4, 'weight_decay': 1e-05}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 3. Training Loop for this combination\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     valid_loss, valid_acc = evaluate_epoch(model, valid_iterator, criterion)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m valid_acc > best_valid_acc:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, iterator, optimizer, criterion)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_epoch\u001b[39m(model, iterator, optimizer, criterion):\n\u001b[32m     48\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\nlp_project\\Lib\\site-packages\\torchtext\\data\\iterator.py:156\u001b[39m, in \u001b[36mIterator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    155\u001b[39m             minibatch.sort(key=\u001b[38;5;28mself\u001b[39m.sort_key, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.repeat:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\nlp_project\\Lib\\site-packages\\torchtext\\data\\batch.py:34\u001b[39m, in \u001b[36mBatch.__init__\u001b[39m\u001b[34m(self, data, dataset, device)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     33\u001b[39m     batch = [\u001b[38;5;28mgetattr\u001b[39m(x, name) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[43mfield\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\nlp_project\\Lib\\site-packages\\torchtext\\data\\field.py:237\u001b[39m, in \u001b[36mField.process\u001b[39m\u001b[34m(self, batch, device)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Process a list of examples to create a torch.Tensor.\u001b[39;00m\n\u001b[32m    227\u001b[39m \n\u001b[32m    228\u001b[39m \u001b[33;03mPad, numericalize, and postprocess a batch and create a tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m \u001b[33;03m    and custom postprocessing Pipeline.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    236\u001b[39m padded = \u001b[38;5;28mself\u001b[39m.pad(batch)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumericalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\nlp_project\\Lib\\site-packages\\torchtext\\data\\field.py:332\u001b[39m, in \u001b[36mField.numericalize\u001b[39m\u001b[34m(self, arr, device)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    331\u001b[39m     arr, lengths = arr\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     lengths = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_vocab:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sequential:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Get Static Parameters ===\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "EMBEDDING_DIM = create_embedding_layer().embedding_dim\n",
    "N_EPOCHS = 10 # Train each combo for 10 epochs\n",
    "\n",
    "grid_search_results = []\n",
    "total_runs = len(hyperparam_combos)\n",
    "\n",
    "print(f\"--- Starting REFINED Grid Search for {total_runs} combinations ---),This will take some time.\")\n",
    "\n",
    "for i, params in enumerate(hyperparam_combos):\n",
    "    run_num = i + 1\n",
    "    print(f\"\\n{'='*20} RUN {run_num}/{total_runs} {'='*20}\")\n",
    "    print(f\"Params: {params}\")\n",
    "    \n",
    "    # 1. Instantiate Model\n",
    "    model = BiRNN_Model(\n",
    "        model_type=params['model_type'],\n",
    "        emb_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        n_layers=params['n_layers'],\n",
    "        bidirectional=True,\n",
    "        dropout=params['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # 2. Instantiate Optimizer and Criterion\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        weight_decay=params['weight_decay'] # Add L2\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_valid_acc = -1.0\n",
    "    start_run_time = time.time()\n",
    "    \n",
    "    # 3. Training Loop for this combination\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_epoch(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate_epoch(model, valid_iterator, criterion)\n",
    "        \n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "    \n",
    "    end_run_time = time.time()\n",
    "    run_duration_mins = (end_run_time - start_run_time) / 60\n",
    "    \n",
    "    # 4. Store Results\n",
    "    result = params.copy()\n",
    "    result['best_valid_acc'] = best_valid_acc * 100 # As percentage\n",
    "    result['time_mins'] = run_duration_mins\n",
    "    grid_search_results.append(result)\n",
    "    \n",
    "    print(f\"Run {run_num} complete. Time: {run_duration_mins:.2f}m. Best Valid Acc: {best_valid_acc*100:.2f}%\")\n",
    "\n",
    "print(\"\\n--- REFINED GRID SEARCH COMPLETE ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a1596",
   "metadata": {},
   "source": [
    "## 5. Analyze Results\n",
    "\n",
    "Now we can load all the new results into a `pandas.DataFrame` to find the winning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refined Hyperparameter Tuning Results ---)(Ranked by Best Validation Accuracy)\n",
      "| model_type   |   hidden_dim |   n_layers |   dropout |   weight_decay |   best_valid_acc |   time_mins |\n",
      "|:-------------|-------------:|-----------:|----------:|---------------:|-----------------:|------------:|\n",
      "| BiGRU        |          512 |          4 |       0.6 |          5e-06 |          88.4549 |   0.234842  |\n",
      "| BiGRU        |          384 |          2 |       0.4 |          1e-05 |          88.2812 |   0.0972018 |\n",
      "| BiGRU        |          384 |          2 |       0.6 |          5e-06 |          88.2812 |   0.0919387 |\n",
      "| BiGRU        |          384 |          2 |       0.4 |          5e-06 |          87.7604 |   0.0912761 |\n",
      "| BiGRU        |          512 |          2 |       0.4 |          5e-06 |          87.7604 |   0.177418  |\n",
      "| BiGRU        |          256 |          3 |       0.6 |          1e-05 |          87.6736 |   0.13361   |\n",
      "| BiLSTM       |          512 |          2 |       0.6 |          5e-05 |          87.5868 |   0.142118  |\n",
      "| BiGRU        |          512 |          2 |       0.6 |          5e-06 |          87.5868 |   0.131879  |\n",
      "| BiGRU        |          512 |          3 |       0.4 |          5e-05 |          87.5    |   0.186511  |\n",
      "| BiGRU        |          256 |          4 |       0.6 |          5e-05 |          87.5    |   0.139799  |\n",
      "| BiGRU        |          512 |          4 |       0.5 |          1e-05 |          87.5    |   0.240767  |\n",
      "| BiGRU        |          512 |          3 |       0.6 |          1e-05 |          87.5    |   0.209226  |\n",
      "| BiGRU        |          512 |          2 |       0.4 |          5e-05 |          87.4132 |   0.148432  |\n",
      "| BiGRU        |          256 |          3 |       0.5 |          5e-06 |          87.3264 |   0.119193  |\n",
      "| BiLSTM       |          384 |          3 |       0.4 |          1e-05 |          87.2396 |   0.137334  |\n",
      "| BiGRU        |          256 |          2 |       0.5 |          1e-05 |          87.2396 |   0.0998009 |\n",
      "| BiGRU        |          256 |          3 |       0.4 |          5e-06 |          87.2396 |   0.109582  |\n",
      "| BiGRU        |          512 |          3 |       0.4 |          5e-06 |          87.2396 |   0.184271  |\n",
      "| BiGRU        |          384 |          3 |       0.4 |          1e-05 |          87.2396 |   0.13782   |\n",
      "| BiLSTM       |          512 |          3 |       0.4 |          5e-06 |          87.1528 |   0.211996  |\n",
      "| BiLSTM       |          384 |          3 |       0.4 |          5e-06 |          87.066  |   0.139396  |\n",
      "| BiGRU        |          256 |          3 |       0.5 |          5e-05 |          87.066  |   0.119664  |\n",
      "| BiLSTM       |          384 |          2 |       0.5 |          1e-05 |          87.066  |   0.0997628 |\n",
      "| BiGRU        |          384 |          2 |       0.6 |          1e-05 |          87.066  |   0.0942611 |\n",
      "| BiLSTM       |          256 |          3 |       0.4 |          5e-05 |          87.066  |   0.102761  |\n",
      "| BiLSTM       |          256 |          2 |       0.6 |          5e-06 |          87.066  |   0.079401  |\n",
      "| BiGRU        |          384 |          4 |       0.4 |          5e-05 |          86.9792 |   0.166251  |\n",
      "| BiLSTM       |          256 |          2 |       0.4 |          1e-05 |          86.9792 |   0.0759087 |\n",
      "| BiLSTM       |          256 |          2 |       0.5 |          5e-05 |          86.9792 |   0.0794609 |\n",
      "| BiLSTM       |          256 |          3 |       0.5 |          5e-06 |          86.9792 |   0.102644  |\n",
      "| BiGRU        |          384 |          4 |       0.6 |          5e-06 |          86.9792 |   0.220019  |\n",
      "| BiLSTM       |          256 |          3 |       0.4 |          1e-05 |          86.8924 |   0.102783  |\n",
      "| BiLSTM       |          384 |          4 |       0.4 |          5e-05 |          86.8924 |   0.191195  |\n",
      "| BiLSTM       |          512 |          4 |       0.5 |          5e-06 |          86.8924 |   0.292597  |\n",
      "| BiLSTM       |          384 |          4 |       0.6 |          5e-06 |          86.8924 |   0.196138  |\n",
      "| BiGRU        |          256 |          2 |       0.4 |          1e-05 |          86.8924 |   0.0926842 |\n",
      "| BiLSTM       |          384 |          4 |       0.5 |          5e-06 |          86.8056 |   0.196929  |\n",
      "| BiLSTM       |          512 |          2 |       0.4 |          1e-05 |          86.8056 |   0.141072  |\n",
      "| BiGRU        |          512 |          3 |       0.6 |          5e-06 |          86.8056 |   0.204601  |\n",
      "| BiGRU        |          256 |          2 |       0.4 |          5e-06 |          86.7188 |   0.090817  |\n",
      "| BiLSTM       |          512 |          2 |       0.5 |          5e-05 |          86.7188 |   0.143183  |\n",
      "| BiLSTM       |          512 |          2 |       0.4 |          5e-06 |          86.7188 |   0.146398  |\n",
      "| BiLSTM       |          256 |          2 |       0.4 |          5e-06 |          86.7188 |   0.0862252 |\n",
      "| BiLSTM       |          256 |          2 |       0.4 |          5e-05 |          86.7188 |   0.0792188 |\n",
      "| BiGRU        |          384 |          4 |       0.5 |          1e-05 |          86.6319 |   0.170704  |\n",
      "| BiGRU        |          256 |          3 |       0.6 |          5e-06 |          86.6319 |   0.114537  |\n",
      "| BiLSTM       |          512 |          4 |       0.5 |          5e-05 |          86.6319 |   0.29747   |\n",
      "| BiGRU        |          384 |          4 |       0.4 |          5e-06 |          86.5451 |   0.169421  |\n",
      "| BiGRU        |          384 |          2 |       0.5 |          5e-06 |          86.5451 |   0.100383  |\n",
      "| BiGRU        |          384 |          2 |       0.5 |          1e-05 |          86.5451 |   0.102938  |\n",
      "| BiLSTM       |          384 |          2 |       0.4 |          1e-05 |          86.5451 |   0.0977108 |\n",
      "| BiGRU        |          384 |          3 |       0.4 |          5e-05 |          86.5451 |   0.136625  |\n",
      "| BiGRU        |          384 |          3 |       0.6 |          5e-06 |          86.4583 |   0.145428  |\n",
      "| BiGRU        |          512 |          2 |       0.5 |          5e-06 |          86.4583 |   0.148023  |\n",
      "| BiGRU        |          256 |          3 |       0.4 |          1e-05 |          86.4583 |   0.113118  |\n",
      "| BiGRU        |          384 |          2 |       0.5 |          5e-05 |          86.4583 |   0.10621   |\n",
      "| BiLSTM       |          384 |          2 |       0.5 |          5e-05 |          86.4583 |   0.103436  |\n",
      "| BiLSTM       |          256 |          3 |       0.5 |          5e-05 |          86.4583 |   0.109847  |\n",
      "| BiLSTM       |          256 |          2 |       0.5 |          5e-06 |          86.3715 |   0.0756041 |\n",
      "| BiLSTM       |          256 |          4 |       0.6 |          5e-05 |          86.3715 |   0.134726  |\n",
      "| BiGRU        |          512 |          4 |       0.4 |          5e-06 |          86.3715 |   0.236143  |\n",
      "| BiLSTM       |          384 |          4 |       0.5 |          5e-05 |          86.3715 |   0.188963  |\n",
      "| BiLSTM       |          384 |          2 |       0.6 |          5e-05 |          86.2847 |   0.10393   |\n",
      "| BiLSTM       |          384 |          3 |       0.6 |          1e-05 |          86.2847 |   0.15129   |\n",
      "| BiLSTM       |          384 |          2 |       0.6 |          1e-05 |          86.2847 |   0.10317   |\n",
      "| BiLSTM       |          256 |          3 |       0.6 |          5e-05 |          86.2847 |   0.104584  |\n",
      "| BiLSTM       |          512 |          2 |       0.6 |          5e-06 |          86.2847 |   0.141599  |\n",
      "| BiGRU        |          384 |          4 |       0.6 |          1e-05 |          86.2847 |   0.211372  |\n",
      "| BiLSTM       |          512 |          4 |       0.6 |          1e-05 |          86.2847 |   0.298506  |\n",
      "| BiGRU        |          384 |          3 |       0.4 |          5e-06 |          86.2847 |   0.136517  |\n",
      "| BiGRU        |          512 |          2 |       0.6 |          1e-05 |          86.2847 |   0.130589  |\n",
      "| BiGRU        |          256 |          2 |       0.5 |          5e-06 |          86.2847 |   0.105615  |\n",
      "| BiLSTM       |          256 |          2 |       0.5 |          1e-05 |          86.1979 |   0.0830267 |\n",
      "| BiLSTM       |          256 |          4 |       0.4 |          5e-06 |          86.1979 |   0.132771  |\n",
      "| BiLSTM       |          512 |          3 |       0.4 |          5e-05 |          86.1979 |   0.212416  |\n",
      "| BiLSTM       |          512 |          3 |       0.6 |          5e-05 |          86.1979 |   0.213668  |\n",
      "| BiGRU        |          256 |          2 |       0.6 |          5e-05 |          86.1979 |   0.0874849 |\n",
      "| BiLSTM       |          256 |          2 |       0.6 |          5e-05 |          86.1111 |   0.0827964 |\n",
      "| BiGRU        |          512 |          3 |       0.5 |          5e-06 |          86.1111 |   0.198388  |\n",
      "| BiGRU        |          384 |          2 |       0.6 |          5e-05 |          86.1111 |   0.0994702 |\n",
      "| BiGRU        |          512 |          2 |       0.5 |          1e-05 |          86.1111 |   0.158319  |\n",
      "| BiLSTM       |          256 |          3 |       0.4 |          5e-06 |          86.1111 |   0.108057  |\n",
      "| BiGRU        |          384 |          3 |       0.5 |          5e-06 |          86.0243 |   0.142874  |\n",
      "| BiGRU        |          512 |          4 |       0.5 |          5e-06 |          86.0243 |   0.233361  |\n",
      "| BiGRU        |          256 |          2 |       0.6 |          5e-06 |          86.0243 |   0.081063  |\n",
      "| BiGRU        |          256 |          3 |       0.4 |          5e-05 |          86.0243 |   0.110486  |\n",
      "| BiLSTM       |          512 |          3 |       0.6 |          1e-05 |          86.0243 |   0.215112  |\n",
      "| BiLSTM       |          384 |          4 |       0.6 |          1e-05 |          86.0243 |   0.200274  |\n",
      "| BiGRU        |          384 |          3 |       0.6 |          1e-05 |          85.9375 |   0.139843  |\n",
      "| BiLSTM       |          512 |          4 |       0.4 |          5e-06 |          85.9375 |   0.292131  |\n",
      "| BiLSTM       |          384 |          2 |       0.6 |          5e-06 |          85.9375 |   0.100619  |\n",
      "| BiLSTM       |          256 |          3 |       0.6 |          1e-05 |          85.9375 |   0.104889  |\n",
      "| BiLSTM       |          512 |          2 |       0.5 |          5e-06 |          85.9375 |   0.142744  |\n",
      "| BiGRU        |          384 |          4 |       0.5 |          5e-05 |          85.8507 |   0.186932  |\n",
      "| BiLSTM       |          256 |          2 |       0.6 |          1e-05 |          85.8507 |   0.0819149 |\n",
      "| BiGRU        |          256 |          3 |       0.5 |          1e-05 |          85.8507 |   0.120368  |\n",
      "| BiLSTM       |          384 |          3 |       0.6 |          5e-06 |          85.8507 |   0.147019  |\n",
      "| BiGRU        |          512 |          4 |       0.5 |          5e-05 |          85.8507 |   0.235084  |\n",
      "| BiLSTM       |          512 |          3 |       0.4 |          1e-05 |          85.7639 |   0.21239   |\n",
      "| BiGRU        |          512 |          4 |       0.4 |          1e-05 |          85.7639 |   0.237782  |\n",
      "| BiGRU        |          256 |          3 |       0.6 |          5e-05 |          85.7639 |   0.119122  |\n",
      "| BiLSTM       |          256 |          4 |       0.5 |          5e-05 |          85.7639 |   0.129421  |\n",
      "| BiGRU        |          384 |          4 |       0.5 |          5e-06 |          85.7639 |   0.172556  |\n",
      "| BiGRU        |          256 |          4 |       0.5 |          5e-06 |          85.6771 |   0.212006  |\n",
      "| BiLSTM       |          512 |          3 |       0.5 |          5e-06 |          85.6771 |   0.214798  |\n",
      "| BiGRU        |          384 |          3 |       0.5 |          1e-05 |          85.6771 |   0.131656  |\n",
      "| BiLSTM       |          256 |          4 |       0.5 |          5e-06 |          85.6771 |   0.13178   |\n",
      "| BiLSTM       |          384 |          2 |       0.4 |          5e-06 |          85.6771 |   0.0975931 |\n",
      "| BiLSTM       |          256 |          3 |       0.6 |          5e-06 |          85.6771 |   0.108665  |\n",
      "| BiGRU        |          384 |          2 |       0.4 |          5e-05 |          85.5903 |   0.0926319 |\n",
      "| BiLSTM       |          512 |          2 |       0.4 |          5e-05 |          85.5903 |   0.141459  |\n",
      "| BiLSTM       |          512 |          3 |       0.5 |          1e-05 |          85.5903 |   0.218167  |\n",
      "| BiLSTM       |          256 |          4 |       0.4 |          1e-05 |          85.5903 |   0.131271  |\n",
      "| BiLSTM       |          256 |          4 |       0.4 |          5e-05 |          85.5903 |   0.132647  |\n",
      "| BiGRU        |          512 |          3 |       0.4 |          1e-05 |          85.5903 |   0.186693  |\n",
      "| BiGRU        |          512 |          2 |       0.6 |          5e-05 |          85.5903 |   0.145556  |\n",
      "| BiLSTM       |          512 |          4 |       0.4 |          1e-05 |          85.5903 |   0.288911  |\n",
      "| BiLSTM       |          512 |          4 |       0.5 |          1e-05 |          85.5035 |   0.289183  |\n",
      "| BiGRU        |          512 |          4 |       0.4 |          5e-05 |          85.5035 |   0.23235   |\n",
      "| BiLSTM       |          384 |          2 |       0.4 |          5e-05 |          85.5035 |   0.0985471 |\n",
      "| BiGRU        |          256 |          2 |       0.5 |          5e-05 |          85.5035 |   0.100714  |\n",
      "| BiLSTM       |          512 |          4 |       0.4 |          5e-05 |          85.5035 |   0.293467  |\n",
      "| BiGRU        |          384 |          3 |       0.5 |          5e-05 |          85.5035 |   0.129339  |\n",
      "| BiGRU        |          256 |          4 |       0.5 |          1e-05 |          85.5035 |   0.15314   |\n",
      "| BiGRU        |          512 |          4 |       0.6 |          5e-05 |          85.5035 |   0.278337  |\n",
      "| BiLSTM       |          384 |          4 |       0.6 |          5e-05 |          85.4167 |   0.198042  |\n",
      "| BiLSTM       |          512 |          4 |       0.6 |          5e-05 |          85.4167 |   0.296521  |\n",
      "| BiLSTM       |          512 |          3 |       0.5 |          5e-05 |          85.4167 |   0.215877  |\n",
      "| BiLSTM       |          384 |          3 |       0.4 |          5e-05 |          85.3299 |   0.138028  |\n",
      "| BiLSTM       |          512 |          3 |       0.6 |          5e-06 |          85.3299 |   0.21503   |\n",
      "| BiLSTM       |          384 |          4 |       0.5 |          1e-05 |          85.1562 |   0.192562  |\n",
      "| BiGRU        |          384 |          3 |       0.6 |          5e-05 |          85.1562 |   0.131279  |\n",
      "| BiLSTM       |          384 |          4 |       0.4 |          5e-06 |          85.0694 |   0.198057  |\n",
      "| BiGRU        |          512 |          3 |       0.6 |          5e-05 |          85.0694 |   0.238758  |\n",
      "| BiGRU        |          256 |          2 |       0.4 |          5e-05 |          85.0694 |   0.0917453 |\n",
      "| BiLSTM       |          384 |          3 |       0.5 |          1e-05 |          85.0694 |   0.142843  |\n",
      "| BiGRU        |          256 |          4 |       0.4 |          1e-05 |          85.0694 |   0.149332  |\n",
      "| BiLSTM       |          256 |          3 |       0.5 |          1e-05 |          84.9826 |   0.10663   |\n",
      "| BiGRU        |          256 |          4 |       0.6 |          5e-06 |          84.9826 |   0.150027  |\n",
      "| BiGRU        |          256 |          4 |       0.5 |          5e-05 |          84.9826 |   0.136042  |\n",
      "| BiLSTM       |          512 |          2 |       0.6 |          1e-05 |          84.809  |   0.141576  |\n",
      "| BiLSTM       |          512 |          4 |       0.6 |          5e-06 |          84.809  |   0.29445   |\n",
      "| BiGRU        |          256 |          4 |       0.6 |          1e-05 |          84.809  |   0.131946  |\n",
      "| BiLSTM       |          384 |          3 |       0.5 |          5e-05 |          84.7222 |   0.144344  |\n",
      "| BiLSTM       |          512 |          2 |       0.5 |          1e-05 |          84.6354 |   0.141243  |\n",
      "| BiLSTM       |          256 |          4 |       0.6 |          1e-05 |          84.6354 |   0.133447  |\n",
      "| BiGRU        |          512 |          3 |       0.5 |          5e-05 |          84.5486 |   0.211385  |\n",
      "| BiGRU        |          256 |          4 |       0.4 |          5e-06 |          84.5486 |   0.140519  |\n",
      "| BiLSTM       |          384 |          2 |       0.5 |          5e-06 |          84.5486 |   0.0995265 |\n",
      "| BiLSTM       |          384 |          3 |       0.5 |          5e-06 |          84.5486 |   0.142783  |\n",
      "| BiLSTM       |          384 |          3 |       0.6 |          5e-05 |          84.5486 |   0.170407  |\n",
      "| BiGRU        |          512 |          2 |       0.4 |          1e-05 |          84.4618 |   0.166724  |\n",
      "| BiGRU        |          256 |          2 |       0.6 |          1e-05 |          84.375  |   0.0810329 |\n",
      "| BiGRU        |          256 |          4 |       0.4 |          5e-05 |          84.2882 |   0.184452  |\n",
      "| BiGRU        |          512 |          4 |       0.6 |          1e-05 |          84.2014 |   0.23148   |\n",
      "| BiLSTM       |          384 |          4 |       0.4 |          1e-05 |          83.941  |   0.209766  |\n",
      "| BiGRU        |          384 |          4 |       0.6 |          5e-05 |          83.941  |   0.21305   |\n",
      "| BiGRU        |          512 |          2 |       0.5 |          5e-05 |          83.6806 |   0.137389  |\n",
      "| BiLSTM       |          256 |          4 |       0.5 |          1e-05 |          83.5069 |   0.133506  |\n",
      "| BiGRU        |          384 |          4 |       0.4 |          1e-05 |          83.4201 |   0.170966  |\n",
      "| BiGRU        |          512 |          3 |       0.5 |          1e-05 |          83.2465 |   0.195094  |\n",
      "| BiLSTM       |          256 |          4 |       0.6 |          5e-06 |          80.9896 |   0.13641   |\n",
      "\n",
      "✓ Saved BiLSTM results to grid_search_results_BiLSTM.json\n",
      "✓ Saved BiGRU results to grid_search_results_BiGRU.json\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(grid_search_results)\n",
    "\n",
    "results_df = results_df.sort_values(by='best_valid_acc', ascending=False)\n",
    "\n",
    "print(\"--- Refined Hyperparameter Tuning Results ---)(Ranked by Best Validation Accuracy)\")\n",
    "print(results_df.to_markdown(index=False, floatfmt=\".6g\"))\n",
    "\n",
    "# Filter the results by model type\n",
    "bilstm_df = results_df[results_df[\"model_type\"] == \"BiLSTM\"]\n",
    "bigru_df  = results_df[results_df[\"model_type\"] == \"BiGRU\"]\n",
    "\n",
    "# Save new JSON files\n",
    "bilstm_json_path = \"grid_search_results_BiLSTM.json\"\n",
    "bigru_json_path  = \"grid_search_results_BiGRU.json\"\n",
    "\n",
    "bilstm_df.to_json(bilstm_json_path, orient=\"records\", indent=4)\n",
    "bigru_df.to_json(bigru_json_path,  orient=\"records\", indent=4)\n",
    "\n",
    "print(f\"\\n✓ Saved BiLSTM results to {bilstm_json_path}\")\n",
    "print(f\"✓ Saved BiGRU results to {bigru_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dced4",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1.  This notebook has created new `grid_search_results_BiLSTM.json` and `grid_search_results_BiGRU.json` files.\n",
    "2.  Look at the table above and identify the **new best-performing hyperparameters** for both BiLSTM and BiGRU.\n",
    "3.  Go to your `Advanced_RNN_Models.ipynb` notebook.\n",
    "4.  **Update the hyperparameters** in cells #11 (for BiLSTM) and #15 (for BiGRU) to match these new winning combinations.\n",
    "5.  Re-run the `Advanced_RNN_Models.ipynb` notebook to get your final, reproducible results for your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
